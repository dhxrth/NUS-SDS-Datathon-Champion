{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhxrth/NUS-SDS-Datathon-Champion/blob/main/NUS_DATATHON_CHAMPION_NUS_146.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Our Analysis\n",
        "\n",
        "In this analysis, we are analysing sales perfomance of both local and domestic businessess. In this particular case we have combined the domestic and international sales performance of the companies. This motivated by the need for the analysis of the overall sales of a company instead of distinct categories.\n",
        "\n",
        "To begin the processing, we started with cleaning the data. By removing the data that we thought was unnecccessary, for instance we removed 14,813 rows of data. This data includes, null data under independent factors, latitude, longtitude, accountid, 8digit sic code and its description, company description which made the data set unreliable and unusable, which adversely affects the ability of our modelling.\n",
        "\n",
        "After removal, we compared the odds ratio of all independent variables to figure out which those are significant enough to be included in our models.\n",
        "\n",
        "We cannot remove variables removing logistic regression, to identify which variables to remove using p-value as the response variable is not binary.\n",
        "\n",
        "Odds ratio can only be calculated for ordinal and categorical variables but non of our remaining variables are as such.\n",
        "\n",
        "By comparing multiple models and comparing their performance indicators such as FPR, FNR, and AUC. We deemed that the best model was KNN as it was the most accurate in predicting the values, which will then help the companies make informed and strategic decisions."
      ],
      "metadata": {
        "id": "IbbnJPJZ1bV6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neDCiJWkJNJK"
      },
      "source": [
        "# Data Preparation\n",
        "\n",
        "The number of empty fields in the \"Year Found\" category was only around 1.6% of the enire dataset, so those rows were removed. An Age column, which shows the difference between the year the company was found and 2024, as the last column.\n",
        "\n",
        "The association between the response variables and quantitative input variables were determined using correlation values. The correlation values between the response variable \"Domestic Ultimate Sales\" and \"Age\" were tabulated to be -0.0165515 which indicates a weak negative correlation. Since \"Global Ultimate Sales\" and \"Domestic Ultimate Sales\" are key response variables, the rows with NA were removed as well. The correlation values between the response variable \"Domestic Ultimate Sales\" and \"Domestic Ultimate Employees\" were tabulated to be 0.01638367 which indicates a weak positive correlation. The correlation values between the response variable \"Global Ultimate Sales\" and \"Global Ultimate Employees\" were tabulated to be 0.6634766 which indicates a strong positive correlation.\n",
        "\n",
        "The association between categorical input variables and the response variables were identified using boxplots and the respective means. The mean (means1) Domestic Ultimate Sales was higher by 7.873727 times when the company is not the ultimate or highest-level company within a corporate structure based in its home country (Is Domestic Ultimate = 0). The mean Global Ultimate Sales (means2) was higher by 13.37533 times when Is Global Ultimate = 0. When comparing mean Global Ultimate Sales (means3) and a companies import/export status, companies that do both import and export recorded the highest mean sales. When comparing the industry of a company and their mean Global Ultimate Sales (means4), the top 5 industries were Petroleum Refining, Air Courier Services, Miscellaneous Business Credit Institutions, Plastics Bottles, Television Broadcasting Stations. When comparing the entity type of a company and their mean Global Ultimate Sales (means5), independently owned companies were ranked the highest. When comparing the parent country of a company and their mean Global Ultimate Sales (means6), the top 5 countries were Finland, Mexico, Bahamas, Ireland and Switzerland. When comparing the ownership type of a company and their mean Global Ultimate Sales (means7), privately owned companies were ranked the highest. When comparing the Global Ultimate Country of a company and their mean Global Ultimate Sales (means8), the top 5 countries were Mexico, United States, Japan, Germany and Taiwan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgl4LZSiJNJT"
      },
      "outputs": [],
      "source": [
        "set.seed(146)\n",
        "data = read.csv('catA_train.csv')\n",
        "getwd()\n",
        "setwd('/Users/siddharth/Desktop/DSA1101')\n",
        "dim(data)\n",
        "head(data)\n",
        "table(Year.Found)\n",
        "length(Year.Found)\n",
        "table(is.na(Year.Found))\n",
        "434/(434+28748)\n",
        "#only 1.4% age empty so remove them\n",
        "data = data[!is.na(data$Year.Found),]\n",
        "dim(data)\n",
        "table(is.na(data$Year.Found))\n",
        "Age = c(2024 - data$Year.Found)\n",
        "data = cbind(data, Age)\n",
        "cor(data$Sales..Domestic.Ultimate.Total.USD.,data$Age)\n",
        "data = data[!is.na(data$Employees..Global.Ultimate.Total.),]\n",
        "cor(data$Sales..Global.Ultimate.Total.USD.,data$Employees..Global.Ultimate.Total.)\n",
        "table(is.na(data$Employees..Domestic.Ultimate.Total.))\n",
        "data = data[!is.na(data$Employees..Domestic.Ultimate.Total.),]\n",
        "cor(data$Sales..Domestic.Ultimate.Total.USD.,data$Employees..Domestic.Ultimate.Total.)\n",
        "boxplot(data$Sales..Domestic.Ultimate.Total.USD.~data$Is.Domestic.Ultimate)\n",
        "means1 <- tapply(data$Sales..Domestic.Ultimate.Total.USD., data$Is.Domestic.Ultimate, mean)\n",
        "means1\n",
        "boxplot(data$Sales..Global.Ultimate.Total.USD.~data$Is.Global.Ultimate)\n",
        "means2 <- tapply(data$Sales..Global.Ultimate.Total.USD., data$Is.Global.Ultimate, mean)\n",
        "means2\n",
        "boxplot(data$Sales..Global.Ultimate.Total.USD.~data$Import.Export.Status)\n",
        "means3 <- tapply(data$Sales..Global.Ultimate.Total.USD., data$Import.Export.Status, mean)\n",
        "means3\n",
        "head(table(data$Industry))\n",
        "boxplot(data$Sales..Global.Ultimate.Total.USD.~data$Industry)\n",
        "means4 <- tapply(data$Sales..Global.Ultimate.Total.USD., data$Industry, mean)\n",
        "means4 = sort(means4, decreasing = TRUE)\n",
        "means4[1:5]\n",
        "boxplot(data$Sales..Global.Ultimate.Total.USD.~data$Entity.Type)\n",
        "table(data$Entity.Type)\n",
        "means5 <- tapply(data$Sales..Global.Ultimate.Total.USD., data$Entity.Type, mean)\n",
        "means5\n",
        "boxplot(data$Sales..Global.Ultimate.Total.USD.~data$Parent.Country)\n",
        "table(data$Parent.Country)\n",
        "means6 <- tapply(data$Sales..Global.Ultimate.Total.USD., data$Parent.Country, mean)\n",
        "means6 = sort(means6, decreasing = TRUE)\n",
        "means6[1:5]\n",
        "data$Ownership.Type\n",
        "table(data$Ownership.Type)\n",
        "boxplot(data$Sales..Global.Ultimate.Total.USD.~data$Ownership.Type)\n",
        "means7 <- tapply(data$Sales..Global.Ultimate.Total.USD., data$Ownership.Type, mean)\n",
        "means7\n",
        "boxplot(data$Sales..Global.Ultimate.Total.USD.~data$Global.Ultimate.Country)\n",
        "means8 <- tapply(data$Sales..Global.Ultimate.Total.USD., data$Global.Ultimate.Country, mean)\n",
        "means8 = sort(means8, decreasing = TRUE)\n",
        "means8[1:5]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bikqlnv2JNJe"
      },
      "source": [
        "# Predictions using Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5SoG5DmJNJf"
      },
      "outputs": [],
      "source": [
        "set.seed(1101)\n",
        "setwd(\"/Users/tech26/Desktop/NUS/MISC/Datathon\")\n",
        "sales <- read.csv(\"datathon9.csv\")\n",
        "attach(sales)\n",
        "# data has been cleaned\n",
        "\n",
        "sales <- sales[, -which(names(sales) == \"SIC.Code\")]\n",
        "# SIC.Code has been removed\n",
        "sales <- sales[, -which(names(sales) == \"X8.Digit.SIC.Description\")]\n",
        "# X8.digit sic description has been removed\n",
        "sales <- sales[, -which(names(sales) == \"X\")]\n",
        "# removing row numbers\n",
        "sales <- sales[, -which(names(sales) == \"Import.Export.Status\")]\n",
        "#removing import export status\n",
        "sales <- sales[, -which(names(sales) == \"Parent.Company\")]\n",
        "# removing Parent.Company\n",
        "sales <- sales[, -which(names(sales) == \"Global.Ultimate.Company\")]\n",
        "#removing Global.Ultimate.Company\n",
        "sales <- sales[, -which(names(sales) == \"Domestic.Ultimate.Company\")]\n",
        "#removing Domestic.Ultimate.Company\n",
        "\n",
        "dim(sales)\n",
        "sales$Total_Sales <- sales$Sales..Global.Ultimate.Total.USD. + sales$Sales..Domestic.Ultimate.Total.USD.\n",
        "# combine the sales data together\n",
        "sales$Total_Sales <- sales$Sales..Global.Ultimate.Total.USD. + sales$Sales..Domestic.Ultimate.Total.USD.\n",
        "sales$Total_employess <- sales$Employees..Domestic.Ultimate.Total. + sales$Employees..Global.Ultimate.Total. + sales$Employees..Single.Site.\n",
        "\n",
        "sales <- sales[, -which(names(sales) == \"Sales..Global.Ultimate.Total.USD.\")]\n",
        "sales <- sales[, -which(names(sales) == \"Sales..Domestic.Ultimate.Total.USD.\")]\n",
        "# removing the individual sales data\n",
        "\n",
        "sales <- sales[, -which(names(sales) == \"Employees..Domestic.Ultimate.Total.\")]\n",
        "sales <- sales[, -which(names(sales) == \"Employees..Global.Ultimate.Total.\")]\n",
        "sales <- sales[, -which(names(sales) == \"Employees..Single.Site.\")]\n",
        "# removing the individual employeees data\n",
        "\n",
        "sales$Entity.Type = as.factor(sales$Entity.Type)\n",
        "sales$Parent.Country  = as.factor(sales$Parent.Country)\n",
        "sales$Ownership.Type = as.factor(sales$Ownership.Type)\n",
        "sales$Global.Ultimate.Country = as.factor(sales$Global.Ultimate.Country)\n",
        "sales$Is.Domestic.Ultimate = as.factor(sales$Is.Domestic.Ultimate)\n",
        "sales$Is.Global.Ultimate = as.factor(sales$Is.Global.Ultimate)\n",
        "sales$Industry = as.factor(sales$Industry)\n",
        "\n",
        "### ANALYSING DATA SET\n",
        "dim(sales)\n",
        "head(sales)\n",
        "summary(sales)\n",
        "# min, 1st, median, mean, mean, 3rd, max of each column\n",
        "\n",
        "# Based on odds ratio of the variables, we reject the variables of odds ratio 0.8-1.2\n",
        "# Variables  \"PhysHlth\", \"Sex\", \"Income\"as these have a weak association with the reponse variable\n",
        "\n",
        "### SPLITTING DATA INTO TRAIN AND TEST SETS\n",
        "# test data : train data <- 1:4\n",
        "# test and train data will have equal percentage of positive and negative response\n",
        "n_folds = 5\n",
        "folds_sales <- sample(rep(1:n_folds, length.out = dim(sales)[1] ))\n",
        "\n",
        "table(folds_sales)\n",
        "\n",
        "# negative_data = diabetes[1:35346,] # Only negtaive resposne data\n",
        "\n",
        "\n",
        "### DECISION TREE CLASSIFIER\n",
        "\n",
        "acc_1 = numeric(n_folds)\n",
        "err_1 = numeric(n_folds)\n",
        "fpr_values_1 = numeric(n_folds)\n",
        "fnr_values_1 = numeric(n_folds)\n",
        "\n",
        "library(rpart)\n",
        "for (j in 1:n_folds){\n",
        "  test_sales <- which(folds_sales == j)\n",
        "\n",
        "  train_sales = sales[ -test_sales, ]\n",
        "  test_sales = sales[test_sales, ]\n",
        "\n",
        "  train = rbind(train_sales, train_sales)\n",
        "  test = rbind(test_sales, test_sales)\n",
        "\n",
        "  model_decision_tree <- rpart(Total_Sales ~ .,\n",
        "                               method = \"class\", data =train, control = rpart.control( minsplit =1),\n",
        "                               parms = list( split ='information'))\n",
        "  pred = predict(model_decision_tree, newdata = test[,2:14], type = 'class')\n",
        "  confusion.matrix = table(pred, test[,1])\n",
        "\n",
        "  TP <- confusion.matrix[2, 2]\n",
        "  TN <- confusion.matrix[1, 1]\n",
        "  FP <- confusion.matrix[1, 2]\n",
        "  FN <- confusion.matrix[2, 1]\n",
        "  fpr_values_1[j] <- FP / (FP + TN)\n",
        "  fnr_values_1[j] <- FN / (FN + TP)\n",
        "\n",
        "  acc_1[j] = sum(diag(confusion.matrix))/sum(confusion.matrix)\n",
        "  err_1[j] = 1 - sum(diag(confusion.matrix))/sum(confusion.matrix)\n",
        "\n",
        "\n",
        "}\n",
        "acc_decision_tree = mean(acc_1); acc_decision_tree # accuracy rate\n",
        "err_decision_tree = mean(err_1); err_decision_tree # error rate\n",
        "fpr_values_decision_tree = mean(fpr_values_1); fpr_values_decision_tree # FPR rate\n",
        "fnr_values_decision_tree = mean(fnr_values_1); fnr_values_decision_tree # FPR rate\n",
        "\n",
        "\n",
        "library(ROCR)\n",
        "has_sales <- predict(model_decision_tree, sales[,2:14], type='class')\n",
        "has_sales = as.numeric(paste(has_sales))\n",
        "pred_dt = prediction(has_sales, Total_Sales)\n",
        "roc_dt = performance(pred_dt, measure=\"tpr\", x.measure=\"fpr\")\n",
        "plot(roc_dt)\n",
        "auc_dc = performance(pred_dt , measure =\"auc\")\n",
        "auc_dc@y.values[[1]] # AUC value\n",
        "\n",
        "### KNN CLASSIFIER\n",
        "\n",
        "acc_2 = numeric(n_folds)\n",
        "err_2 = numeric(n_folds)\n",
        "fpr_values_2 = numeric(n_folds)\n",
        "fnr_values_2 = numeric(n_folds)\n",
        "\n",
        "library(class)\n",
        "# Doing knn from 1 to 100\n",
        "K = 100\n",
        "\n",
        "accuracy = numeric(K)\n",
        "\n",
        "random <- 5\n",
        "test_sales <- which(folds_sales == random)\n",
        "\n",
        "train_sales = negative_data[ -test_sales, ]\n",
        "test_nej = negative_data[test_sales, ]\n",
        "\n",
        "train_knn = rbind(train_sales)\n",
        "test_knn = rbind(test_sales)\n",
        "\n",
        "# We do the n folds loop outside of the K loop so as to ensrue the program runs in a reasonable amount of time\n",
        "for (i in 1:K) {\n",
        "  pred <- knn(train = train_knn[, 2:14], test = test_knn[, 2:14], cl = train_knn[,1], k = i)\n",
        "  accuracy[i]= mean(test_knn[,1] == pred)\n",
        "}\n",
        "which(accuracy == max(accuracy))\n",
        "\n",
        "# The model that gves the best accuracy is k = 88\n",
        "\n",
        "for (j in 1:n_folds){\n",
        "  test_sales <- which(folds_sales == j)\n",
        "\n",
        "  train_sales = negative_data[ -test_sales, ]\n",
        "  test_sales = negative_data[test_sales, ]\n",
        "\n",
        "  train_knn = rbind(train_sales, train_sales)\n",
        "  test_knn = rbind(test_sales, test_sales)\n",
        "\n",
        "  model_knn <- knn(train = train_knn[, 2:14], test = test_knn[, 2:14], cl = train_knn$Total_Sales, k = 88)\n",
        "  confusion.matrix = table(model_knn, test_knn[,1])\n",
        "\n",
        "  TP <- confusion.matrix[2, 2]\n",
        "  TN <- confusion.matrix[1, 1]\n",
        "  FP <- confusion.matrix[1, 2]\n",
        "  FN <- confusion.matrix[2, 1]\n",
        "  fpr_values_2[j] <- FP / (FP + TN)\n",
        "  fnr_values_2[j] <- FN / (FN + TP)\n",
        "\n",
        "  acc_2[j] = sum(diag(confusion.matrix))/sum(confusion.matrix)\n",
        "  err_2[j] = 1 - sum(diag(confusion.matrix))/sum(confusion.matrix)\n",
        "}\n",
        "\n",
        "acc_knn = mean(acc_2); acc_knn # accuracy rate\n",
        "err_knn = mean(err_2); err_knn # error rate\n",
        "fpr_values_knn = mean(fpr_values_2); fpr_values_knn # FPR rate\n",
        "fnr_values_knn = mean(fnr_values_2); fnr_values_knn # FPR rate\n",
        "\n",
        "library(ROCR)\n",
        "library(class)\n",
        "has_sales <- knn(train = train_knn[, 2:14], test = sales[,2:14], cl = train_knn$Total_Sales, k = 88)\n",
        "has_sales = as.numeric(has_sales)\n",
        "pred_knn = prediction(has_sales, Total_Sales)\n",
        "roc_knn = performance(pred_knn, measure=\"tpr\", x.measure=\"fpr\")\n",
        "plot(roc_knn)\n",
        "auc_knn = performance(pred_knn , measure =\"auc\")\n",
        "auc_knn@y.values[[1]] # AUC value\n",
        "\n",
        "\n",
        "### LOGISTIC REGRESSION CLASSIFIER\n",
        "\n",
        "acc_3 = numeric(n_folds)\n",
        "err_3 = numeric(n_folds)\n",
        "fpr_values_3 = numeric(n_folds)\n",
        "fnr_values_3 = numeric(n_folds)\n",
        "\n",
        "\n",
        "library(rpart)\n",
        "library(\"rpart.plot\")\n",
        "for (j in 1:n_folds){\n",
        "  test_sales <- which(folds_sales == j)\n",
        "\n",
        "  train_sales = sales_data[ -test_sales, ]\n",
        "  test_sales = sales_data[test_sales, ]\n",
        "\n",
        "  train = rbind(train_sales)\n",
        "  test = rbind(test_sales)\n",
        "\n",
        "  model_logistic_regression<- glm(Total_Sales ~ .,\n",
        "                                  data =train,family = binomial(link =\"logit\"))\n",
        "  pred = predict(model_logistic_regression, newdata = test[,2:14], type = 'response')\n",
        "  pred <- ifelse(pred > 0.5, 1, 0)\n",
        "  confusion.matrix = table(pred, test[,1])\n",
        "\n",
        "  TP <- confusion.matrix[2, 2]\n",
        "  TN <- confusion.matrix[1, 1]\n",
        "  FP <- confusion.matrix[1, 2]\n",
        "  FN <- confusion.matrix[2, 1]\n",
        "  fpr_values_3[j] <- FP / (FP + TN)\n",
        "  fnr_values_3[j] <- FN / (FN + TP)\n",
        "\n",
        "  acc_3[j] = sum(diag(confusion.matrix))/sum(confusion.matrix)\n",
        "  err_3[j] = 1 - sum(diag(confusion.matrix))/sum(confusion.matrix)\n",
        "\n",
        "\n",
        "}\n",
        "acc_lr = mean(acc_3); acc_lr # accuracy rate\n",
        "err_lr = mean(err_3); err_lr# error rate\n",
        "fpr_values_lr = mean(fpr_values_3); fpr_values_lr # FPR rate\n",
        "fnr_values_lr = mean(fnr_values_3); fnr_values_lr # FPR rate\n",
        "\n",
        "library(ROCR)\n",
        "has_sales = predict(model_logistic_regression, sales[,2:14], type =\"response\")\n",
        "\n",
        "pred_lr = prediction(has_sales, Total_Sales)\n",
        "roc_lr = performance(pred_lr, measure=\"tpr\", x.measure=\"fpr\")\n",
        "plot(roc_lr)\n",
        "auc_lr = performance(pred_lr , measure =\"auc\")\n",
        "auc_lr@y.values[[1]] # AUC value\n",
        "\n",
        "### NAIVES BAYERS CLASSIFIER\n",
        "\n",
        "acc_4 = numeric(n_folds)\n",
        "err_4 = numeric(n_folds)\n",
        "fpr_values_4 = numeric(n_folds)\n",
        "fnr_values_4 = numeric(n_folds)\n",
        "\n",
        "library(rpart)\n",
        "for (j in 1:n_folds){\n",
        "  test_sales <- which(folds_sales == j)\n",
        "\n",
        "  train_sales = sales_data[ -test_sales, ]\n",
        "  test_sales = sales_data[test_sales, ]\n",
        "\n",
        "  train = rbind(train_sales)\n",
        "  test = rbind(test_sales)\n",
        "\n",
        "  model_nb<- glm(Total_Sales ~ .,\n",
        "                 data =train,family = binomial(link =\"logit\"))\n",
        "  pred = predict(model_logistic_regression, newdata = test[,2:14], type = 'response')\n",
        "  pred <- ifelse(pred > 0.5, 1, 0)\n",
        "  confusion.matrix = table(pred, test[,1])\n",
        "\n",
        "  TP <- confusion.matrix[2, 2]\n",
        "  TN <- confusion.matrix[1, 1]\n",
        "  FP <- confusion.matrix[1, 2]\n",
        "  FN <- confusion.matrix[2, 1]\n",
        "  fpr_values_4[j] <- FP / (FP + TN)\n",
        "  fnr_values_4[j] <- FN / (FN + TP)\n",
        "\n",
        "  acc_4[j] = sum(diag(confusion.matrix))/sum(confusion.matrix)\n",
        "  err_4[j] = 1 - sum(diag(confusion.matrix))/sum(confusion.matrix)\n",
        "\n",
        "\n",
        "}\n",
        "acc_nb = mean(acc_4); acc_nb # accuracy rate\n",
        "err_nb = mean(err_4); err_nb # error rate\n",
        "fpr_values_nb = mean(fpr_values_4); fpr_values_nb # FPR rate\n",
        "fnr_values_nb = mean(fnr_values_4); fnr_values_nb # FPR rate\n",
        "\n",
        "library(ROCR)\n",
        "has_sales = predict(model_nb, sales[,2:14], type =\"response\")\n",
        "\n",
        "pred_nb = prediction(has_sales, Total_Sales)\n",
        "roc_nb = performance(pred_nb, measure=\"tpr\", x.measure=\"fpr\")\n",
        "plot(roc_nb)\n",
        "auc_nb = performance(pred_dt , measure =\"auc\")\n",
        "auc_nb@y.values[[1]] # AUC value\n",
        "\n",
        "# COMPARING THE MODELS\n",
        "# create vector containing all factors to examin goodness of fit\n",
        "ACCURACY <- c(acc_decision_tree, acc_knn, acc_lr, acc_nb);ACCURACY\n",
        "ERROR <- c(err_decision_tree, err_knn, err_lr, err_nb);ERROR\n",
        "FPR <- c(fpr_values_decision_tree, fpr_values_knn, fpr_values_lr, fpr_values_nb);FPR\n",
        "FNR <- c(fnr_values_decision_tree, fnr_values_knn, fnr_values_lr, fnr_values_nb);FNR\n",
        "AUC <- c(auc_dc@y.values[[1]], auc_knn@y.values[[1]], auc_lr@y.values[[1]], auc_nb@y.values[[1]]);AUC\n",
        "\n",
        "highest_accuracy <- which.max(ACCURACY); highest_accuracy\n",
        "lowest_error <- which.min(ERROR); lowest_error\n",
        "lowest_fpr <- which.min(FPR); lowest_fpr\n",
        "lowest_fnr <- which.min(FNR); lowest_fnr\n",
        "highest_auc <- which.max(AUC); highest_auc\n",
        "\n",
        "# Therefore it can be concluded that the logistic regression model is the best model\n",
        "\n",
        "# Comparing predicted response of logistic regression model and thebactual response variable\n",
        "response_best_model <- predict(model_logistic_regression, newdata = sales, type = 'response')\n",
        "\n",
        "# Create side-by-side boxplots\n",
        "boxplot(Total_Sales, response_best_model,\n",
        "        col = c(\"blue\", \"red\"),\n",
        "        xlab = \"Response\",\n",
        "        main = \"Actual vs Predicted Response\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}